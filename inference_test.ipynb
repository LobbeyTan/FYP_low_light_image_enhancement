{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.source import Unet_resize_conv\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nth_training = 48\n",
    "root = r\"C:/Users/ILLEGEAR/OneDrive - Universiti Malaya/FYP/checkpoints/enlightenGAN\"\n",
    "path = f\"{root}/training_{nth_training}/iter_trained\"\n",
    "demo = f\"{root}/demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_baseline = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = torch.nn.DataParallel(Unet_resize_conv(custom_attention=False), [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Loading Model\n",
      "C:/Users/ILLEGEAR/OneDrive - Universiti Malaya/FYP/checkpoints/enlightenGAN/demo\\net_G.pth\n"
     ]
    }
   ],
   "source": [
    "model = baseline if use_baseline else Unet_resize_conv(custom_attention=False)\n",
    "model_pth = os.path.join(demo if use_baseline else path, 'net_G.pth')\n",
    "model.load_state_dict(torch.load(model_pth, device))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Done Loading Model\")\n",
    "print(model_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(size=286, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(size=256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "def getAttentionLayer(image):\n",
    "    r, g, b = image[0] + 1, image[1] + 1, image[2] + 1\n",
    "    grayscale = 1. - (0.299*r + 0.587*g + 0.114*b) / 2.\n",
    "    return torch.unsqueeze(grayscale, dim=0)\n",
    "\n",
    "def transformImage(image: Image.Image, mode='grayscale-1D'):\n",
    "    assert mode in ['grayscale-1D', 'grayscale-3D', 'RGB']\n",
    "    \n",
    "    img = preprocess(image)\n",
    "    att = getAttentionLayer(img)\n",
    "    \n",
    "    if mode == 'grayscale-1D':\n",
    "        r, g, b = img[0], img[1], img[2]\n",
    "        grayscale = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "        img = torch.unsqueeze(grayscale, dim=0)\n",
    "    \n",
    "    if mode == 'grayscale-3D':\n",
    "        r, g, b = img[0], img[1], img[2]\n",
    "        grayscale = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "        img = torch.unsqueeze(grayscale, dim=0)\n",
    "        img = img.repeat(3, 1, 1)\n",
    "    \n",
    "    # Adding batch dimension\n",
    "    img = img.unsqueeze(dim=0).to(device)\n",
    "    att = att.unsqueeze(dim=0).to(device)\n",
    "    \n",
    "    return img, att\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOL = r\"C:\\Users\\ILLEGEAR\\Desktop\\cheelam\\FYP\\Repositories\\FYP_low_light_image_enhancement\\datasets\\light_enhancement\\testA\"\n",
    "EXDARK = r\"C:\\Users\\ILLEGEAR\\Desktop\\cheelam\\FYP\\Repositories\\FYP_low_light_image_enhancement\\datasets\\test\\testA\"\n",
    "SID = r\"C:\\Users\\ILLEGEAR\\Desktop\\cheelam\\FYP\\Repositories\\FYP_low_light_image_enhancement\\datasets\\test\\SID-RGB\"\n",
    "\n",
    "data_root = SID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 120\n",
    "running_times = []\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# GPU Warmup\n",
    "dummy_img = torch.randn(1, 3, 256, 256, dtype=torch.float).to(device)\n",
    "dummy_att = torch.randn(1, 1, 256, 256, dtype=torch.float).to(device)\n",
    "\n",
    "for _ in range(10):\n",
    "    model(dummy_img, dummy_att)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, img_path in enumerate(os.listdir(data_root)):\n",
    "        image = Image.open(os.path.join(data_root, img_path)).convert('RGB')\n",
    "        \n",
    "        img, att = transformImage(image, mode='RGB')\n",
    "        \n",
    "        starter.record()\n",
    "        model(img, att)\n",
    "        ender.record()\n",
    "        \n",
    "        # WAIT FOR GPU SYNC\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        running_times.append(curr_time)\n",
    "            \n",
    "        if (i + 1) >= n_sample:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Running Time (s) for 120 images: 8.236103989601135\n",
      "Average Running Time (s): 0.0686341999133428\n",
      "Average FPS: 14.569995734817264\n"
     ]
    }
   ],
   "source": [
    "total_time = sum(running_times) / 1000\n",
    "avg_time  = total_time / len(running_times)\n",
    "avg_fps = 1 / avg_time\n",
    "\n",
    "print(f\"Total Running Time (s) for {len(running_times)} images:\", total_time)\n",
    "print(\"Average Running Time (s):\", avg_time)\n",
    "print(\"Average FPS:\", avg_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SID_raw = r\"C:\\Users\\ILLEGEAR\\Desktop\\cheelam\\FYP\\Repositories\\FYP_low_light_image_enhancement\\datasets\\test\\SID\"\n",
    "# SID_save = r\"C:\\Users\\ILLEGEAR\\Desktop\\cheelam\\FYP\\Repositories\\FYP_low_light_image_enhancement\\datasets\\test\\SID-RGB\"\n",
    "\n",
    "# import rawpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_filenames = os.listdir(SID_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, filename in enumerate(image_filenames):\n",
    "#     rawimg = rawpy.imread(os.path.join(SID_raw, filename))\n",
    "    \n",
    "#     img = Image.fromarray(rawimg.raw_image)\n",
    "#     img.convert('RGB')\n",
    "#     img.save(os.path.join(SID_save, \"%04d\" % (i+1) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9b618401b2c0edb6095b3a6b1bd3225b1d93920d52d2d6324020ed64f706650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
